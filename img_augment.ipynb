{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-24 22:53:43.700333: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-24 22:53:43.811721: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-24 22:53:44.583262: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvrtc.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-24 22:53:44.583332: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-24 22:53:44.583338: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.data_utils import Sequence\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.keras import balanced_batch_generator\n",
    "\n",
    "from keras.applications.resnet import ResNet50, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.utils import shuffle\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save augmented images into folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BalancedDataGenerator(Sequence):\n",
    "    \"\"\"ImageDataGenerator + RandomOversampling\"\"\"\n",
    "    def __init__(self, X, y, datagen, batch_size=32, save_imgs = False, dir_to_save = ''):\n",
    "        self.datagen = datagen\n",
    "        self.batch_size = min(batch_size, X.shape[0])\n",
    "        self.datagen.fit(X) #datagen.fit(X)\n",
    "        self.balanced_gen, self.steps_per_epoch = balanced_batch_generator(\n",
    "                                        X.reshape(X.shape[0], -1), # shape (n_samples, n_features)\n",
    "                                        y, \n",
    "                                        sampler=RandomOverSampler(), \n",
    "                                        batch_size=self.batch_size, \n",
    "                                        keep_sparse=True,\n",
    "                                        random_state = 2022\n",
    "                                        )\n",
    "        # asterisks * just unpacks the tuple from shape\n",
    "        # For example: (1, X.shape[1:]) = (1, (256, 256, 3))\n",
    "        # while (1, *X.shape[1:]) = (1, 256, 256, 3)\n",
    "        self.img_shape = X.shape[1:] # (256, 256, 3)\n",
    "        self._shape = (self.steps_per_epoch * self.batch_size, *X.shape[1:])\n",
    "        self.save_imgs = save_imgs\n",
    "        self.dir_to_save = dir_to_save\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.steps_per_epoch\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x_batch_balanced, y_batch_balanced = self.balanced_gen.__next__()\n",
    "        x_batch_balanced = x_batch_balanced.reshape(-1, *self.img_shape)\n",
    "        #print(x_batch_balanced.shape, len(y_batch_balanced))\n",
    "        \n",
    "        batches_balanced =  self.datagen.flow(\n",
    "                            x_batch_balanced, y_batch_balanced, \n",
    "                            batch_size=self.batch_size,\n",
    "                            # save_to_dir = self.dir_to_save if self.save_imgs else None,\n",
    "                            # save_prefix = '',\n",
    "                            # save_format = 'jpeg' # for smaller storage size           \n",
    "                            )\n",
    "\n",
    "        # return a pair of X_batch and y_batch \n",
    "        return batches_balanced.next()\n",
    "\n",
    "train_gen = ImageDataGenerator(\n",
    "            rotation_range=15,\n",
    "            fill_mode='constant',\n",
    "            horizontal_flip=True,\n",
    "            zoom_range=0.1,\n",
    "            preprocessing_function=preprocess_input\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta = pd.read_csv('data/Edema/df_Edema_1121.csv')\n",
    "X_all = np.load('data/Edema/X_Edema.npy')\n",
    "print(X_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24704, 256, 256, 3)\n",
      "14614\n",
      "(14614, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "df_used = df_meta['survive'].dropna()\n",
    "y = list(df_used)\n",
    "X = X_all[df_used.index]\n",
    "print(len(y))\n",
    "print(X.shape) # 24704 -> 14614"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of batches: 159\n",
      "folder cleaned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159/159 [02:42<00:00,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array(['DIE', 'SURVIVE'], dtype='<U7'), array([10179,  4435]))\n",
      "(array(['DIE', 'SURVIVE'], dtype='<U7'), array([10175, 10177]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "datagen = train_gen # define your data augmentation\n",
    "save_imgs = True\n",
    "dir_to_save= 'data/Edema/images/balanced'\n",
    "bgen = BalancedDataGenerator(X, y, datagen, batch_size= 128, \n",
    "                        # save_imgs = save_imgs, \n",
    "                        # dir_to_save= dir_to_save\n",
    "                        )\n",
    "\n",
    "steps_per_epoch = bgen.steps_per_epoch\n",
    "print('Total number of batches:', steps_per_epoch)\n",
    "\n",
    "if save_imgs:\n",
    "    if os.path.exists(dir_to_save):\n",
    "        shutil.rmtree(dir_to_save) # clear the folder first if exist\n",
    "        os.mkdir(dir_to_save)\n",
    "        print('folder cleaned')\n",
    "    else:\n",
    "        os.mkdir(dir_to_save)\n",
    "\n",
    "X_gen_l = []\n",
    "y_gen_l = []\n",
    "num_batches_needed = steps_per_epoch\n",
    "for i in tqdm(range(num_batches_needed)): #steps_per_epoch\n",
    "    X_gen, y_gen = bgen.__getitem__(0)\n",
    "    #print(X_gen.shape, len(y_gen))\n",
    "    X_gen_l.append(X_gen)\n",
    "    y_gen_l.append(y_gen)\n",
    "\n",
    "print(np.unique(y, return_counts=True))\n",
    "print(np.unique(y_gen_l, return_counts=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20352, 256, 256, 3) (20352,)\n"
     ]
    }
   ],
   "source": [
    "X_gen_all = np.concatenate(X_gen_l)\n",
    "y_gen_all = np.concatenate(y_gen_l)\n",
    "print(X_gen_all.shape, y_gen_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train/test/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images in training set: 15264\n",
      "Images in validation set: 4070\n",
      "Images in testing set: 1018\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_index</th>\n",
       "      <th>class</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>DIE</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>SURVIVE</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>SURVIVE</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>DIE</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>SURVIVE</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20347</th>\n",
       "      <td>20347</td>\n",
       "      <td>SURVIVE</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20348</th>\n",
       "      <td>20348</td>\n",
       "      <td>DIE</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20349</th>\n",
       "      <td>20349</td>\n",
       "      <td>SURVIVE</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20350</th>\n",
       "      <td>20350</td>\n",
       "      <td>DIE</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20351</th>\n",
       "      <td>20351</td>\n",
       "      <td>SURVIVE</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20352 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       img_index    class    set\n",
       "0              0      DIE  train\n",
       "1              1  SURVIVE  train\n",
       "2              2  SURVIVE    val\n",
       "3              3      DIE  train\n",
       "4              4  SURVIVE  train\n",
       "...          ...      ...    ...\n",
       "20347      20347  SURVIVE   test\n",
       "20348      20348      DIE  train\n",
       "20349      20349  SURVIVE    val\n",
       "20350      20350      DIE  train\n",
       "20351      20351  SURVIVE    val\n",
       "\n",
       "[20352 rows x 3 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# make a dataframe\n",
    "df_gen = pd.DataFrame({'img_index': list(range(X_gen_all.shape[0])), 'class': y_gen_all})\n",
    "unique_id = df_gen.img_index.unique() #data_df.subject_id.unique()\n",
    "\n",
    "train_percent, valid_percent, test_percent = 0.75, 0.20, 0.05\n",
    "\n",
    "unique_id = shuffle(unique_id)\n",
    "value1 = (round(len(unique_id)*train_percent))\n",
    "value2 = (round(len(unique_id)*valid_percent))\n",
    "value3 = value1 + value2\n",
    "value4 = (round(len(unique_id)*test_percent))\n",
    "\n",
    "print(\"Images in training set: \" + str(value1))\n",
    "print(\"Images in validation set: \" + str(value2))\n",
    "print(\"Images in testing set: \" + str(value4))\n",
    "\n",
    "train_sub_id = unique_id[:value1]\n",
    "validate_sub_id = unique_id[value1:value3]\n",
    "test_sub_id = unique_id[value3:]\n",
    "\n",
    "split_l = []\n",
    "for i in range(df_gen.shape[0]):\n",
    "    img_ind = df_gen.img_index[i]\n",
    "    add = ''\n",
    "    if img_ind in train_sub_id:\n",
    "        add = 'train'\n",
    "    elif img_ind in validate_sub_id:\n",
    "        add = 'val'\n",
    "    else:\n",
    "        add = 'test'\n",
    "    split_l.append(add)\n",
    "\n",
    "df_gen['set'] = split_l\n",
    "df_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train    0.75000\n",
       "val      0.19998\n",
       "test     0.05002\n",
       "Name: set, dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gen['set'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save npy array as images in folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease = 'Edema' # 'Pneumonia_Consolidation' , 'No_finding'\n",
    "task = 'survive' # 'race', 'gender', 'insuarance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24704, 256, 256, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20352/20352 [00:27<00:00, 747.58it/s]\n"
     ]
    }
   ],
   "source": [
    "new_folder = f'data/{disease}/images/{task}/balanced'\n",
    "if os.path.exists(new_folder):\n",
    "    shutil.rmtree(new_folder) # clear the folder first if exist\n",
    "DATA_DIR = Path(new_folder)\n",
    "DATASETS = ['train', 'val', 'test']\n",
    "class_names = np.unique(y_gen_all)\n",
    "for ds in DATASETS:\n",
    "    for cls in class_names:\n",
    "        (DATA_DIR / ds / cls).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "img_array = np.load(f'data/{disease}/X_{disease}.npy')\n",
    "print(img_array.shape)\n",
    "for i in tqdm(range(df_gen.shape[0])):\n",
    "    img_ind = df_gen['img_index'][i]\n",
    "    ds = df_gen['set'][i]\n",
    "    cls = df_gen['class'][i]\n",
    "    img = Image.fromarray(img_array[i])\n",
    "    fname = f'{DATA_DIR}/{ds}/{cls}/{i}.jpeg'\n",
    "    img.save(fname)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('cxr_work')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5d44154881edf0404873c4f8c4b335030119e7922735b95b4347ec6c0889b162"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
